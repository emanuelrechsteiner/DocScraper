---
url: https://supabase.com/blog/seen-by-in-postgresql
scraped_at: 2025-05-25T09:07:27.820053
title: Implementing "seen by" functionality with Postgres
---

  1. We use cookies to collect data and improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)
[Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)•Privacy settings
Accept Opt out Privacy settings


[![Supabase Logo](https://supabase.com/_next/image?url=https%3A%2F%2Ffrontend-assets.supabase.com%2Fwww%2Fd218d9190b87%2F_next%2Fstatic%2Fmedia%2Fsupabase-logo-wordmark--light.daaeffd3.png&w=256&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)![Supabase Logo](https://supabase.com/_next/image?url=https%3A%2F%2Ffrontend-assets.supabase.com%2Fwww%2Fd218d9190b87%2F_next%2Fstatic%2Fmedia%2Fsupabase-logo-wordmark--dark.b36ebb5f.png&w=256&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)](https://supabase.com/)
  * Product 
  * Developers 
  * [Enterprise](https://supabase.com/enterprise)
  * [Pricing](https://supabase.com/pricing)
  * [Docs](https://supabase.com/docs)
  * [Blog](https://supabase.com/blog)


[83.3K](https://github.com/supabase/supabase)[Sign in](https://supabase.com/dashboard)[Start your project](https://supabase.com/dashboard)
Open main menu
[Back](https://supabase.com/blog)
[Blog](https://supabase.com/blog)
# Implementing "seen by" functionality with Postgres
18 Jul 2022
•
33 minute read
[![Victor avatar](https://supabase.com/_next/image?url=https%3A%2F%2Fgithub.com%2Ft3hmrman.png&w=96&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)VictorGuest Author](https://github.com/t3hmrman)
![Implementing "seen by" functionality with Postgres](https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fseen-by%2Fseen-by-postgresql-thumb.png&w=3840&q=100&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)
**tl;dr: Use HyperLogLog, it's a reasonable approach with great trade-offs and no large architectural liabilities. For a quick & dirty prototype, use `hstore`, which also performs the best with integer IDs.**
The year is 2022. You're head DBA at the hot new social site, SupaBook... Your startup is seeing eye-boggling growth because everyone loves fitting their hot-takes in posts restricted to `VARCHAR(256)`.
Why `VARCHAR(256)`? No particular reason, but you don't have time to get hung up on that or ask why -- **you just found out that the priority this quarter is tracking content views across all posts in the app**.
"It sounds pretty simple" a colleague at the meeting remarks -- "just an increment here and an increment there and we'll know which posts are seen the most on our platform". You start to explain why it will be non-trivial, but the meeting ends before you can finish.
Well, it's time to figure out how you're going to do it. There's been a complexity freeze at the company, so you're not allowed to bring in any new technology, but you don't mind that because for v1 you would have picked Postgres anyway. Postgres's open source pedigree, robust suite of features, stable internals, and awesome mascot [Slonik](https://www.vertabelo.com/blog/the-history-of-slonik-the-postgresql-elephant-logo/) make it a strong choice, and it's what you're already running.
**_(insert record scratch here)_**
Sure, this scenario isn't real, but it could be - that last part about Postgres definitely is. Let's see how you might solve this problem, as that imaginary DBA.
## Experiment setup[#](https://supabase.com/blog/seen-by-in-postgresql#experiment-setup)
We've got the following simple table layout:
![basic table layout diagram](https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fseen-by%2Fseen-by-postgresql-uml-1.png&w=3840&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)
In SQL migration form:
hideCopy
`
1
CREATE EXTENSION IF NOT EXISTS uuid-ossp;
2
CREATE EXTENSION IF NOT EXISTS citext;
34
-- Create a email domain to represent and constraing email addresses
5
CREATE DOMAIN email
6
AS citext
7
CHECK ( LENGTH(VALUE) <= 255 AND value ~ '^[a-zA-Z0-9.!#$%&''*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$' );
89
COMMENT ON DOMAIN email is 'lightly validated email address';
1011
-- Create the users table
12
CREATE TABLE users (
13
  id bigserial PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
14
  uuid uuid NOT NULL DEFAULT uuid_nonmc_v1(),
1516
  email email NOT NULL,
17
  name text,
18
  about_html text,
1920
  created_at timestamptz NOT NULL DEFAULT NOW()
21
);
2223
-- Create the posts table
24
CREATE TABLE posts (
25
  id bigserial PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
26
  uuid uuid NOT NULL DEFAULT uuid_nonmc_v1(),
2728
  title text,
29
  content text,
30
  main_image_src text,
31
  main_link_src text,
3233
  created_by bigint REFERENCES users(id),
3435
  last_hidden_at timestamptz,
36
  last_updated_at timestamptz,
37
  created_at timestamptz NOT NULL DEFAULT NOW()
38
);
`
This basic setup has taken the (imaginary) company quite far -- even though the `posts` table has millions and millions of entries, Postgres chugs along and serves our queries with impressive speed and reliability. Scaling up is the new (and old) scaling out.
## How should we do it?[#](https://supabase.com/blog/seen-by-in-postgresql#how-should-we-do-it)
Well we can't pat ourselves for our miraculous and suspiciously simple DB architecture all day, let's move on to the task at hand.
Like any good tinkerer we'll start with the simplest solutions and work our way up in complexity to try and get to something outstanding, testing our numbers as we go.
### Try #1: The naive way, a simple counter on every Post[#](https://supabase.com/blog/seen-by-in-postgresql#try-1-the-naive-way-a-simple-counter-on-every-post)
The easiest obvious way to do this is to maintain a counter on every tuple in the `posts` table. It's obvious, and it's almost guaranteed to work -- but maybe not _work well_.
The migration to make it happen isn't too difficult:
hideCopy
`
1
BEGIN;
23
ALTER TABLE posts ADD COLUMN seen_by_count;
45
COMMENT ON COLUMN posts.seen_by_count
6
 IS 'simple count of users who have seen the post';
78
COMMIT;
`
There's one _obvious_ glaring issue here -- what if someone sees the same post twice? Every page reload would cause inflated counts in the `seen_by_count` column, not to mention a lot of concurrent database updates (which isn't necessarily Postgres's forte to begin with).
Clearly there's a better way to do things but before that...
## Writing a test suite before the CPUs get hot and heavy[#](https://supabase.com/blog/seen-by-in-postgresql#writing-a-test-suite-before-the-cpus-get-hot-and-heavy)
How will we know which approach is better without numbers?! Measuring complexity and feeling can only get us so far -- we need to get some numbers that tell us the performance of the solution at the stated tasks -- we need benchmarks.
Before we can declare any solution the best, in particular we need a _baseline!_. The simplest possible incorrect solution (simply incrementing a counter on the Post) is probably a reasonable thing to use as a benchmark, so let's take a moment to write our testing suite.
Let's do this the simplest one might imagine:
  * Generate a large amount of users 
    * Lets model for 1000, 10k, 100K, 1MM, and 10MM users
  * Generate an even larger amount of fake posts attributed to those users 
    * This is a bit harder -- we need to define a general distribution for our users that's somewhat informed by real life...
    * An average/normalized distribution doesn't quite work here -- [on sites like twitter 10% of users create 80% of the tweets](https://www.pewresearch.org/internet/2019/04/24/sizing-up-twitter-users/)!
  * Generate a _description_ of "events" that describe which post was seen by whom, which we can replay. 
    * We want the equivalent of an effect system or monadic computation, which is easier than it sounds -- we want to generate an encoding (JSON, probably) of _what to do_ , without actually doing it
    * We'll just do consistent "as fast as we can" execution (more complicated analysis would burst traffic to be ab it closer to real life)


OK, let's roll our hands up and get it done:
### Script: User seeding[#](https://supabase.com/blog/seen-by-in-postgresql#script-user-seeding)
Here's what that looks like:
`
1
/**
2
 * Generate a list of synthetic users to be loaded into Postgres
3
 *
4
 * @param {object} args
5
 * @param {number} [args.count] number of users to generate
6
 * @param {number} [args.aboutHTMLWordCount] number of words to generate (lorem ipsum) for about_html (serves to add heft to tuples)
7
 * @param {string} [args.outputFilePath] output file path, if present this functoin returns void
8
 * @returns {any[][]} List of generated synthetic users
9
 */
10
export async function generateUsers(args) {
11
 const count = args.count || DEFAULT_USER_COUNT
12
 const aboutHTMLWordCount = args.aboutHTMLWordCount || DEFAULT_ABOUT_HTML_WORD_COUNT
1314
 const outputFilePath = args.outputFilePath
15
 if (!outputFilePath) {
16
  throw new Error('output file path must be specified')
17
 }
1819
 for (var id = 0; id < count; id++) {
20
  const user = {
21
   id,
22
   email: `user${id}@example.com`,
23
   name: `user ${id}`,
24
   about_html: fastLoremIpsum(aboutHTMLWordCount, 'w'),
25
  }
2627
  // Write the entries to disk (returning nothing)
28
  if (args.outputFilePath) {
29
   await appendFile(outputFilePath, `${JSON.stringify(user)}\n`)
30
  }
31
 }
32
}
`
Nothing too crazy in there -- we generate a bunch of JSON, and force it out to disk. It's best to avoid trying to keep it in memory so we can handle much larger volumes than we might be able to fit in memory.
If you'd like to see the code, check out [`scripts/generate/users.js` in the repo](https://github.com/VADOSWARE/supabase-seen-by/blob/main/scripts/generate/users.js).
### Script: Post seeding[#](https://supabase.com/blog/seen-by-in-postgresql#script-post-seeding)
Along with users, we need to generate posts that they can view. We'll keep it simple and take an amount of posts to make, generating from 0 to `count` of those.
It's very similar to the user generation code, with the caveat that we can take into account the 80/20 lurker/poster rule. here's what that looks like:
It's a bit long so if you'd like to see the code, check out [`scripts/generate/posts.js` in the repo](https://github.com/VADOSWARE/supabase-seen-by/blob/main/scripts/generate/posts.js).
### Script: action (API call) seeding/generation[#](https://supabase.com/blog/seen-by-in-postgresql#script-action-api-call-seedinggeneration)
This script is a bit tricky -- we need to inject some randomness in the performing of the following actions:
  * Record a new view of a post
  * Retrieve just the count of a single post
  * Retrieve all the users who saw a post


I've chosen to use [`autocannon`](https://www.npmjs.com/package/autocannon) so I needed to write a request generation script which looks like this:
`
1
const process = require('process')
23
const POST_COUNT = process.env.TEST_POST_COUNT
4
 ? parseInt(process.env.TEST_POST_COUNT, 10)
5
 : undefined
6
const USER_COUNT = process.env.TEST_USER_COUNT
7
 ? parseInt(process.env.TEST_USER_COUNT, 10)
8
 : undefined
910
/**
11
 * Request setup function for use with autocannon
12
 *
13
 * @param {Request} request
14
 * @returns {Request}
15
 */
16
function setupRequest(request) {
17
 // ENsure we have counts to go off of
18
 if (!POST_COUNT || !USER_COUNT) {
19
  throw new Error('Cannot setup request without valid post/user count!')
20
 }
2122
 // Pick a random post to do an operation on
23
 const postId = Math.floor(Math.random() * POST_COUNT)
2425
 // Choose pseudo-randomly whether to register a seen by or read seenby status
26
 const operationChoice = Math.floor(Math.random() * 10)
27
 if (operationChoice < 1) {
28
  // 10% of the time, get *all* the users
29
  request.method = 'GET'
30
  request.path = `/posts/${postId}/seen-by/users`
31
 } else if (operationChoice < 7) {
32
  // 60% of the time, get the count of seenby on a post
33
  request.method = 'GET'
34
  request.path = `/posts/${postId}/seen-by/count`
35
 } else {
36
  // 30% of the time, add a new seen-by entry
37
  const userId = Math.floor(Math.random() * USER_COUNT)
3839
  // Most of the time we'll be *setting* seen-by
40
  // And we'll get the count (so we can show it) later as well
41
  request.method = 'POST'
42
  request.path = `/posts/${postId}/seen-by/${userId}`
43
 }
4445
 return request
46
}
4748
module.exports = setupRequest
`
Nothing too crazy here, and some back of the envelope estimations on how often each operation would normally be called. These numbers could be tweaked more, but we _should_ see a difference between approaches even if we messed up massively here.
If you'd like to see the code, check out [`scripts/setup-request.cjs` in the repo](https://github.com/VADOSWARE/supabase-seen-by/blob/main/scripts/setup-request.cjs).
### Glue it all together[#](https://supabase.com/blog/seen-by-in-postgresql#glue-it-all-together)
Once we're done we need to glue this all together into one script, with roughly this format:
`
1
export default async function runBenchmark() {
2
 // Start the server
3
 // Reset before test
4
 // Generate & insert users
5
 // Generate & insert posts
6
 // Generate actions (API Calls) to run
7
 // Execute the API calls
8
 // Write JSON results to tmpdir
9
 // Stop the server
10
}
`
If you want to see what the code _actually_ ended up looking like, check out [`scripts/bench.js` in the repo](https://github.com/VADOSWARE/supabase-seen-by/blob/main/scripts/bench.js).
Along with the benchmark, we'll standardize on the following settings:
`
1
export SEEN_BY_STRATEGY=simple-counter # or: simple-hstore, assoc-table, hll
2
export TEST_USERS_JSON_PATH=/tmp/supabase-seen-by.users.json
3
export TEST_POSTS_JSON_PATH=/tmp/supabase-seen-by.posts.json
4
export TEST_POST_COUNT=1000
5
export TEST_USER_COUNT=100000
6
export TEST_DURATION_SECONDS=60
78
## Use custom postgres image built with hll extension (https://github.com/citusdata/postgresql-hll)
9
## NOTE: `make db-custom-image` must be run beforehand
10
#export DB_IMAGE=postgres-14.4-alpine-hll
11
#export DB_IMAGE_TAG=latest
`
### Our first run, on the naive solution[#](https://supabase.com/blog/seen-by-in-postgresql#our-first-run-on-the-naive-solution)
Alright, finally we're ready. Let's see what we get on our naive solution. We expect this to be _pretty fast_ , because not only is it _wrong_ , but it's just about the simplest thing you could do.
On my local machine, here's our baseline (output from [`autocannon`](https://www.npmjs.com/package/autocannon)):
`
1
┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
2
│ Stat  │ 2.5% │ 50% │ 97.5% │ 99% │ Avg   │ Stdev  │ Max  │
3
├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
4
│ Latency │ 0 ms │ 2 ms │ 6 ms │ 6 ms │ 2.03 ms │ 1.82 ms │ 23 ms │
5
└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
6
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
7
│ Stat   │ 1%   │ 2.5%  │ 50%   │ 97.5%  │ Avg   │ Stdev  │ Min   │
8
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
9
│ Req/Sec  │ 297   │ 318   │ 389   │ 500   │ 391.24 │ 47.87  │ 297   │
10
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
11
│ Bytes/Sec │ 54.1 kB │ 57.9 kB │ 70.8 kB │ 91.1 kB │ 71.3 kB │ 8.72 kB │ 54.1 kB │
12
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
1314
Req/Bytes counts sampled once per second.
15
# of samples: 60
1617
┌────────────┬──────────────┐
18
│ Percentile │ Latency (ms) │
19
├────────────┼──────────────┤
20
│ 0.001   │ 0      │
21
├────────────┼──────────────┤
22
│ 0.01    │ 0      │
23
├────────────┼──────────────┤
24
│ 0.1    │ 0      │
25
├────────────┼──────────────┤
26
│ 1     │ 0      │
27
├────────────┼──────────────┤
28
│ 2.5    │ 0      │
29
├────────────┼──────────────┤
30
│ 10     │ 0      │
31
├────────────┼──────────────┤
32
│ 25     │ 0      │
33
├────────────┼──────────────┤
34
│ 50     │ 2      │
35
├────────────┼──────────────┤
36
│ 75     │ 3      │
37
├────────────┼──────────────┤
38
│ 90     │ 5      │
39
├────────────┼──────────────┤
40
│ 97.5    │ 6      │
41
├────────────┼──────────────┤
42
│ 99     │ 6      │
43
├────────────┼──────────────┤
44
│ 99.9    │ 9      │
45
├────────────┼──────────────┤
46
│ 99.99   │ 16      │
47
├────────────┼──────────────┤
48
│ 99.999   │ 23      │
49
└────────────┴──────────────┘
5051
23k requests in 60.02s, 4.28 MB read
`
As you might imagine, pretty darn good latency across all the requests.
## Back to trying things out[#](https://supabase.com/blog/seen-by-in-postgresql#back-to-trying-things-out)
Now that we've got a basic baseline of our tests, let's continue trying out ideas:
### Try #2: Storing the users who did the "see"ing, with `hstore`[#](https://supabase.com/blog/seen-by-in-postgresql#try-2-storing-the-users-who-did-the-seeing-with-hstore)
The next obvious thing (and probably a core requirement if we'd asked around), is knowing _who_ viewed each post. Well if we need to know who, then we probably need to store some more information!
Postgres has [native support for arrays](https://www.postgresql.org/docs/current/arrays.html) and [a data structure called a `hstore`](https://www.postgresql.org/docs/current/hstore.html), so let's try those. It's pretty obvious that having hundreds, thousands, or millions of entries in one of these data structures, inside a tuple isn't the _greatest_ idea, but let's try it anyway and let the numbers speak for themselves.
Here's what the migration would look like:
hideCopy
`
1
BEGIN;
23
CREATE EXTENSION IF NOT EXISTS hstore;
45
ALTER TABLE posts ADD COLUMN seen_count_hstore hstore
6
 NOT NULL DEFAULT ''::hstore;
78
COMMENT ON COLUMN posts.seen_count_hstore
9
 IS 'count of users that have seen the post, with hstore';
1011
COMMIT;
`
`hstore` provides support for both [GIST](https://www.postgresql.org/docs/14/indexes-types.html#INDEXES-TYPE-GIST) and [GIN](https://www.postgresql.org/docs/14/indexes-types.html#INDEXES-TYPES-GIN) indices, but after reading [the documentation](https://www.postgresql.org/docs/current/hstore.html#id-1.11.7.25.7) we can conclude that we don't necessarily need those for the current set of functionality.
#### Caveats[#](https://supabase.com/blog/seen-by-in-postgresql#caveats)
Well as you might have imagined, this is obviously pretty bad and will eventually be hard to scale. If you expect only 0-50 entries in your column `text[]` is perfectly fine, but thousands or millions is another ballgame.
Thinking of how to scale this, a few ideas pop to mind:
  * Compress our columns with [LZ4](https://github.com/lz4/lz4) which is newly supported [`TOAST` column compression](https://www.postgresql.org/docs/current/storage-toast.html) (I first heard about this thanks to [Fujitsu's fantastic blog post](https://www.postgresql.fastware.com/blog/what-is-the-new-lz4-toast-compression-in-postgresql-14))
  * `PARTITION` our `posts` table


#### Performance[#](https://supabase.com/blog/seen-by-in-postgresql#performance)
OK, time to get on with it, let's see how it performs with an `hstore`:
`
1
┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
2
│ Stat  │ 2.5% │ 50% │ 97.5% │ 99% │ Avg   │ Stdev  │ Max  │
3
├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
4
│ Latency │ 0 ms │ 2 ms │ 5 ms │ 6 ms │ 2.15 ms │ 1.67 ms │ 16 ms │
5
└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
6
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
7
│ Stat   │ 1%   │ 2.5%  │ 50%   │ 97.5%  │ Avg   │ Stdev  │ Min   │
8
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
9
│ Req/Sec  │ 287   │ 305   │ 348   │ 504   │ 369.12 │ 58.8  │ 287   │
10
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
11
│ Bytes/Sec │ 53.9 kB │ 56.9 kB │ 64.5 kB │ 92.5 kB │ 68.3 kB │ 10.7 kB │ 53.8 kB │
12
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
1314
Req/Bytes counts sampled once per second.
15
# of samples: 60
1617
┌────────────┬──────────────┐
18
│ Percentile │ Latency (ms) │
19
├────────────┼──────────────┤
20
│ 0.001   │ 0      │
21
├────────────┼──────────────┤
22
│ 0.01    │ 0      │
23
├────────────┼──────────────┤
24
│ 0.1    │ 0      │
25
├────────────┼──────────────┤
26
│ 1     │ 0      │
27
├────────────┼──────────────┤
28
│ 2.5    │ 0      │
29
├────────────┼──────────────┤
30
│ 10     │ 0      │
31
├────────────┼──────────────┤
32
│ 25     │ 1      │
33
├────────────┼──────────────┤
34
│ 50     │ 2      │
35
├────────────┼──────────────┤
36
│ 75     │ 3      │
37
├────────────┼──────────────┤
38
│ 90     │ 5      │
39
├────────────┼──────────────┤
40
│ 97.5    │ 5      │
41
├────────────┼──────────────┤
42
│ 99     │ 6      │
43
├────────────┼──────────────┤
44
│ 99.9    │ 9      │
45
├────────────┼──────────────┤
46
│ 99.99   │ 9      │
47
├────────────┼──────────────┤
48
│ 99.999   │ 16      │
49
└────────────┴──────────────┘
5051
22k requests in 60.02s, 4.1 MB read
`
Not too far off! While we didn't try the pathological case(s) of millions of people liking the _same_ post to hit breaking point, a slightly more random distribution seems to have done decently -- we actually have _lower_ 99.999th percentile latency versus the simple counter.
An average of `2.15ms` versus `2.05ms` with the simpler counter is a ~4% increase in the average latency (though of course, the p99.999 is lower!).
### Try #3: An Association table for remembering who liked what[#](https://supabase.com/blog/seen-by-in-postgresql#try-3-an-association-table-for-remembering-who-liked-what)
A likely requirement from the original scenario that we've completely ignored is remembering _which_ users liked a certain post to. The easiest solution here is an "associative" table like this one:
![tables with associative table](https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fseen-by%2Fseen-by-postgresql-uml-2.png&w=3840&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)
In SQL:
hideCopy
`
1
begin;
23
create table posts_seen_by_users (
4
 post_id bigint references posts (id),
5
 user_id bigint references users (id),
6
 seen_count bigint not null default 0 check (seen_count > 0),
7
 primary key (post_id, user_id)
8
);
910
commit;
`
#### Caveats[#](https://supabase.com/blog/seen-by-in-postgresql#caveats-1)
In production, you're going to want to do a few things to make this even remotely reasonable long term:
  * `PARTITION` the table (consider using partition-friendly [`pg_partman`](https://github.com/pgpartman/pg_partman))
  * Move old partitions off to slower/colder storage and maintain snapshots
  * Summarize older content that might be seen lots
  * Consider a partitioning key up front -- post IDs are probably a reasonable thing to use if they're sufficiently randomly distributed


These are good initial stop-gaps, but a realistic setup will have many problems and many more solutions to be discovered.
(It will be a recurring theme but this is a spot where _we probably don't necessarily want to use stock Postgres_ but instead want to use tools like [Citus Columnar Storage](https://docs.citusdata.com/en/stable/admin_guide/table_management.html#columnar-storage), [ZedStore](https://github.com/greenplum-db/postgres/tree/zedstore), or an external choice like [ClickHouse](https://clickhouse.com)).
#### Performance[#](https://supabase.com/blog/seen-by-in-postgresql#performance-1)
Alright, enough dilly dally, let's run our test bench against this setup:
`
1
┌─────────┬──────┬──────┬───────┬──────┬────────┬─────────┬───────┐
2
│ Stat  │ 2.5% │ 50% │ 97.5% │ 99% │ Avg  │ Stdev  │ Max  │
3
├─────────┼──────┼──────┼───────┼──────┼────────┼─────────┼───────┤
4
│ Latency │ 0 ms │ 2 ms │ 8 ms │ 8 ms │ 2.5 ms │ 2.45 ms │ 30 ms │
5
└─────────┴──────┴──────┴───────┴──────┴────────┴─────────┴───────┘
6
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
7
│ Stat   │ 1%   │ 2.5%  │ 50%   │ 97.5%  │ Avg   │ Stdev  │ Min   │
8
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
9
│ Req/Sec  │ 238   │ 254   │ 321   │ 464   │ 326.52 │ 48.14  │ 238   │
10
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
11
│ Bytes/Sec │ 43.4 kB │ 46.3 kB │ 58.5 kB │ 84.5 kB │ 59.5 kB │ 8.77 kB │ 43.3 kB │
12
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
1314
Req/Bytes counts sampled once per second.
15
# of samples: 60
1617
┌────────────┬──────────────┐
18
│ Percentile │ Latency (ms) │
19
├────────────┼──────────────┤
20
│ 0.001   │ 0      │
21
├────────────┼──────────────┤
22
│ 0.01    │ 0      │
23
├────────────┼──────────────┤
24
│ 0.1    │ 0      │
25
├────────────┼──────────────┤
26
│ 1     │ 0      │
27
├────────────┼──────────────┤
28
│ 2.5    │ 0      │
29
├────────────┼──────────────┤
30
│ 10     │ 0      │
31
├────────────┼──────────────┤
32
│ 25     │ 1      │
33
├────────────┼──────────────┤
34
│ 50     │ 2      │
35
├────────────┼──────────────┤
36
│ 75     │ 4      │
37
├────────────┼──────────────┤
38
│ 90     │ 7      │
39
├────────────┼──────────────┤
40
│ 97.5    │ 8      │
41
├────────────┼──────────────┤
42
│ 99     │ 8      │
43
├────────────┼──────────────┤
44
│ 99.9    │ 11      │
45
├────────────┼──────────────┤
46
│ 99.99   │ 25      │
47
├────────────┼──────────────┤
48
│ 99.999   │ 30      │
49
└────────────┴──────────────┘
5051
20k requests in 60.02s, 3.57 MB read
`
A little bit more divergence here -- 99.999%ile latency @ 30 which is almost double what it was for simple-hstore.
Average is coming in at `2.50ms` which is 16% slower than simple-hstore and 21% slower than simple-counter.
### Try #4: Getting a bit more serious: bringing out the HyperLogLog[#](https://supabase.com/blog/seen-by-in-postgresql#try-4-getting-a-bit-more-serious-bringing-out-the-hyperloglog)
![rest of the owl](https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fseen-by%2Frest-of-owl.png&w=3840&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)
We'll just draw [the rest of the owl](https://knowyourmeme.com/memes/how-to-draw-an-owl) now.
What's [HyperLogLog](https://en.wikipedia.org/wiki/HyperLogLog) you ask? Well it's just a probabilistic data structure! Don't worry if you've never heard of it before, it's a reasonably advanced concept.
You may have heard of [Bloom Filters](https://en.wikipedia.org/wiki/Bloom_filter) and they're _somewhat_ related but they're not quite a great fit for the problem we're solving since we want to know how many people have seen a particular post. Knowing whether one user has seen a particular post is useful too -- but not quite what we're solving for here (and we'd have to double-check our false positives anyway if we wanted to be absolutely sure).
HyperLogLog provides a probabilistic data structure that is good at counting _distinct_ entries, so that means that the count _will not_ be exact, but be reasonably close (depending on how we tune). We won't have false positives (like with a bloom filter) -- we'll have a degree of error (i.e. the actual count may be 1000, but the HLL reports 1004).
We have to take this into account on the UI side but and maybe retrieve the full count if anyone ever _really_ needs to know/view individual users that have seen the content, so we can fall back to our association table there.
Given that [every second there are about 6000 tweets on Twitter(!)](https://www.internetlivestats.com/twitter-statistics/), this is probably one of the only solutions that could actually work at massive scale with the limitations we've placed on ourselves.
Here's what that looks like in SQL:
hideCopy
`
1
BEGIN;
23
CREATE EXTENSION IF NOT EXISTS hll;
45
ALTER TABLE posts ADD COLUMN seen_count_hll hll
6
 NOT NULL DEFAULT hll_empty();
78
COMMENT ON COLUMN posts.seen_count_hll
9
 IS 'HyperLogLog storing user IDs';
1011
COMMIT;
`
Here we need the [`citus/postgresql-hll`](https://github.com/citusdata/postgresql-hll) extension, which is generously made ([truly](https://github.com/citusdata/postgresql-hll/blob/master/LICENSE)) open source by [citusdata](https://www.citusdata.com/).
NOTE that we still have access to the association table -- and while we still insert rows into it, we can _drop_ the primary key index, and simply update our HLL (and leave ourselves a note on when we last updated it).
### Caveats[#](https://supabase.com/blog/seen-by-in-postgresql#caveats-2)
There's not much to add to this solution, as the heavy lifting is mostly done by `postgresql-hll`, but there's one big caveat:
  * This approach _will_ need a custom Postgres image for this, since `hll` is not an official `contrib` module


There are also a few optimizations that are easy to imagine:
  * Batching inserts to the association table (storing them in some other medium in the meantime -- local disk, redis, etc)
  * Writing our association table entries in a completely different storage medium altogether (like object storage) and use [Foreign Data Wrappers](https://www.postgresql.org/docs/current/postgres-fdw.html) and [`pg_cron`](https://github.com/citusdata/pg_cron) and delay or put off processing all together


### Performance[#](https://supabase.com/blog/seen-by-in-postgresql#performance-2)
The most complicated solution by far, let's see how it fares:
`
1
┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
2
│ Stat  │ 2.5% │ 50% │ 97.5% │ 99% │ Avg   │ Stdev  │ Max  │
3
├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
4
│ Latency │ 0 ms │ 2 ms │ 6 ms │ 6 ms │ 2.28 ms │ 2.03 ms │ 59 ms │
5
└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
6
┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
7
│ Stat   │ 1%   │ 2.5%  │ 50%   │ 97.5%  │ Avg   │ Stdev  │ Min   │
8
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
9
│ Req/Sec  │ 272   │ 285   │ 351   │ 456   │ 353.05 │ 45.13  │ 272   │
10
├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
11
│ Bytes/Sec │ 49.5 kB │ 51.9 kB │ 63.9 kB │ 83.1 kB │ 64.3 kB │ 8.22 kB │ 49.5 kB │
12
└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
1314
Req/Bytes counts sampled once per second.
15
# of samples: 60
1617
┌────────────┬──────────────┐
18
│ Percentile │ Latency (ms) │
19
├────────────┼──────────────┤
20
│ 0.001   │ 0      │
21
├────────────┼──────────────┤
22
│ 0.01    │ 0      │
23
├────────────┼──────────────┤
24
│ 0.1    │ 0      │
25
├────────────┼──────────────┤
26
│ 1     │ 0      │
27
├────────────┼──────────────┤
28
│ 2.5    │ 0      │
29
├────────────┼──────────────┤
30
│ 10     │ 0      │
31
├────────────┼──────────────┤
32
│ 25     │ 1      │
33
├────────────┼──────────────┤
34
│ 50     │ 2      │
35
├────────────┼──────────────┤
36
│ 75     │ 4      │
37
├────────────┼──────────────┤
38
│ 90     │ 6      │
39
├────────────┼──────────────┤
40
│ 97.5    │ 6      │
41
├────────────┼──────────────┤
42
│ 99     │ 6      │
43
├────────────┼──────────────┤
44
│ 99.9    │ 9      │
45
├────────────┼──────────────┤
46
│ 99.99   │ 28      │
47
├────────────┼──────────────┤
48
│ 99.999   │ 59      │
49
└────────────┴──────────────┘
5051
21k requests in 60.03s, 3.86 MB read
`
Another somewhat nuanced degradation in performance -- while the 99.99%ile latency was nearly 2x higher, the average latency was actually _lower_ than the assoc-table approach @ `2.28ms`.
The average latency on the HLL approach is 11% worse than simple-counter, 6% worse than simple-hstore, and _faster_ than assoc-table alone, which is an improvement.
### Oh, the other places we could go[#](https://supabase.com/blog/seen-by-in-postgresql#oh-the-other-places-we-could-go)
One of the great things about Postgres is it's expansive ecosystem -- while Postgres may (and frankly _should not_) beat the perfect specialist tool for your use case, it often does an outstanding job in the general case.
Let's look into some more experiments that could be run -- maybe one day in the future we'll get some numbers behind these (community contributions are welcome!).
#### Incremental view maintenance powered by `pg_ivm`[#](https://supabase.com/blog/seen-by-in-postgresql#incremental-view-maintenance-powered-by-pg_ivm)
If you haven't heard about [`pg_ivm`](https://github.com/sraoss/pg_ivm) it's an extension for handling Incremental View Maintenance -- updating [`VIEW`](https://www.postgresql.org/docs/14/sql-createview.html)s when underlying tables change.
IVM is a hotly requested feature whenever views (particularly materialized views) are mentioned, so there has been much fanfare to it's release.
There are a couple advantages we could gain by using `pg_ivm`:
  * Ability to time constrain calculations (newer posts which are more likely to be seen can exist in instant-access views)
  * We could theoretically remove the complicated nature of the HLL all together by using `COUNT` with IVM


`pg_ivm` is quite new and cutting edge but looks to be a great solution -- it's worth giving a shot someday.
### Doing graph computations with [AGE](https://age.apache.org/)[#](https://supabase.com/blog/seen-by-in-postgresql#doing-graph-computations-with-age)
As is usually the case in academia and practice, we can make our problem drastically easier by simply changing the data structures we use to model our problem!
One such reconfiguration would be storing the information as a graph:
![graph of seen by relation](https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fseen-by%2Fgraph-seen-edges.png&w=3840&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)
As you might imagine, finding the number of "seen-by" relations would simply be counting the number of edges out of one of the nodes!
Well, the Postgres ecosystem has us covered here too! [AGE](https://age.apache.org/) is an extension that allows you to perform graph related queries in Postgres.
We won't pursue it in this post but it would be a great way to model this problem as well -- thanks to the extensibility of Postgres, this data could live right next to our normal relational data as well.
## So what's the best way to do it?[#](https://supabase.com/blog/seen-by-in-postgresql#so-whats-the-best-way-to-do-it)
OK, so what's the answer at the end of the day? What's the best way to get to that useful v1? Here are the numbers:
![latency graph showing simple-hstore,hll,hll,and assoc table in speed order](https://supabase.com/_next/image?url=%2Fimages%2Fblog%2Fseen-by%2Fseen-by-chart.png&w=3840&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)
In tabular form:
Approach| Avg (ms)| 99%ile (ms)| 99.999%ile (ms)  
---|---|---|---  
simple-counter| 2.03| 6| 23  
simple-hstore| 2.15| 6| 16  
assoc-table| 2.5| 8| 30  
hll| 2.16| 7| 27  
**If we go strictly with the data, the best way _looks_ to be the `hstore`-powered solution, but I think the HLL is probably the right choice.**
The HLL results were quite variable -- some runs were faster than others, so I've taken the best of 3 runs.
Even though the data says `hstore`, knowing that posts will be seen by more and more people over time, I _might_ choose the HLL solution for an actual implementation. It's far less likely to pose a bloated row problem, and it has the absolute correctness (and later recall) of the assoc-table solution, while performing better over all (as you can imagine, no need to `COUNT` rows).
Another benefit of the HLL solution is that [PostgreSQL tablespaces](https://www.postgresql.org/docs/current/manage-ag-tablespaces.html) allow us to put the association table on a different, slower storage mechanism, and keep our `posts` table fast. Arguably in a real system we might have the HLL in something like `redis` but for a v1, it looks like Postgres does quite well!
# Wrap-up[#](https://supabase.com/blog/seen-by-in-postgresql#wrap-up)
I hope you enjoyed this look down the trunk hole, and you've got an idea of how to implement solutions to surprisingly complex problems like this one with Postgres.
As usual, Postgres has the tools to solve the problem _reasonably_ well (if not completely) before you reach out for more complicated/standalone solutions.
**See any problems with the code, solutions that haven't been tried? -- reach out, or open an issue!**
## More Postgres resources[#](https://supabase.com/blog/seen-by-in-postgresql#more-postgres-resources)
  * [Partial data dumps using Postgres Row Level Security](https://supabase.com/blog/partial-postgresql-data-dumps-with-rls)
  * [Postgres Views](https://supabase.com/blog/postgresql-views)
  * [Postgres Auditing in 150 lines of SQL](https://supabase.com/blog/audit)
  * [Cracking PostgreSQL Interview Questions](https://supabase.com/blog/cracking-postgres-interview)
  * [What are PostgreSQL Templates?](https://supabase.com/blog/postgresql-templates)
  * [Realtime Postgres RLS on Supabase](https://supabase.com/blog/realtime-row-level-security-in-postgresql)


Share this article
[](https://twitter.com/intent/tweet?url=https%3A%2F%2Fsupabase.com%2Fblog%2Fseen-by-in-postgresql&text=Implementing%20%22seen%20by%22%20functionality%20with%20Postgres)[](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fsupabase.com%2Fblog%2Fseen-by-in-postgresql&text=Implementing%20%22seen%20by%22%20functionality%20with%20Postgres)[](https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsupabase.com%2Fblog%2Fseen-by-in-postgresql&t=Implementing%20%22seen%20by%22%20functionality%20with%20Postgres)
[Last postSupabase Flutter SDK 1.0 Developer Preview2 August 2022](https://supabase.com/blog/supabase-flutter-sdk-1-developer-preview)
[Next postRevamped Auth Helpers for Supabase (with SvelteKit support)13 July 2022](https://supabase.com/blog/supabase-auth-helpers-with-sveltekit-support)
[postgres](https://supabase.com/blog/tags/postgres)[planetpg](https://supabase.com/blog/tags/planetpg)
On this page
  * [Experiment setup](https://supabase.com/blog/seen-by-in-postgresql#experiment-setup)
  * [How should we do it?](https://supabase.com/blog/seen-by-in-postgresql#how-should-we-do-it)
    * [Try #1: The naive way, a simple counter on every Post](https://supabase.com/blog/seen-by-in-postgresql#try-1-the-naive-way-a-simple-counter-on-every-post)
  * [Writing a test suite before the CPUs get hot and heavy](https://supabase.com/blog/seen-by-in-postgresql#writing-a-test-suite-before-the-cpus-get-hot-and-heavy)
    * [Script: User seeding](https://supabase.com/blog/seen-by-in-postgresql#script-user-seeding)
    * [Script: Post seeding](https://supabase.com/blog/seen-by-in-postgresql#script-post-seeding)
    * [Script: action (API call) seeding/generation](https://supabase.com/blog/seen-by-in-postgresql#script-action-api-call-seedinggeneration)
    * [Glue it all together](https://supabase.com/blog/seen-by-in-postgresql#glue-it-all-together)
    * [Our first run, on the naive solution](https://supabase.com/blog/seen-by-in-postgresql#our-first-run-on-the-naive-solution)
  * [Back to trying things out](https://supabase.com/blog/seen-by-in-postgresql#back-to-trying-things-out)
    * [Try #2: Storing the users who did the "see"ing, with `hstore`](https://supabase.com/blog/seen-by-in-postgresql#try-2-storing-the-users-who-did-the-seeing-with-hstore)
    * [Try #3: An Association table for remembering who liked what](https://supabase.com/blog/seen-by-in-postgresql#try-3-an-association-table-for-remembering-who-liked-what)
    * [Try #4: Getting a bit more serious: bringing out the HyperLogLog](https://supabase.com/blog/seen-by-in-postgresql#try-4-getting-a-bit-more-serious-bringing-out-the-hyperloglog)
    * [Caveats](https://supabase.com/blog/seen-by-in-postgresql#caveats-2)
    * [Performance](https://supabase.com/blog/seen-by-in-postgresql#performance-2)
    * [Oh, the other places we could go](https://supabase.com/blog/seen-by-in-postgresql#oh-the-other-places-we-could-go)
    * [Doing graph computations with [AGE][age]](https://supabase.com/blog/seen-by-in-postgresql#doing-graph-computations-with-ageage)
  * [So what's the best way to do it?](https://supabase.com/blog/seen-by-in-postgresql#so-whats-the-best-way-to-do-it)


  * [Wrap-up](https://supabase.com/blog/seen-by-in-postgresql#wrap-up)
    * [More Postgres resources](https://supabase.com/blog/seen-by-in-postgresql#more-postgres-resources)


Share this article
[](https://twitter.com/intent/tweet?url=https%3A%2F%2Fsupabase.com%2Fblog%2Fseen-by-in-postgresql&text=Implementing%20%22seen%20by%22%20functionality%20with%20Postgres)[](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fsupabase.com%2Fblog%2Fseen-by-in-postgresql&text=Implementing%20%22seen%20by%22%20functionality%20with%20Postgres)[](https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsupabase.com%2Fblog%2Fseen-by-in-postgresql&t=Implementing%20%22seen%20by%22%20functionality%20with%20Postgres)
## Build in a weekend, scale to millions
[Start your project](https://supabase.com/dashboard)[Request a demo](https://supabase.com/contact/sales)
## Footer
We protect your data.[More on Security](https://supabase.com/security)
  * SOC2 Type 2 Certified
  * HIPAA Compliant


[![Supabase Logo](https://supabase.com/_next/image?url=https%3A%2F%2Ffrontend-assets.supabase.com%2Fwww%2Fd218d9190b87%2F_next%2Fstatic%2Fmedia%2Fsupabase-logo-wordmark--light.daaeffd3.png&w=384&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)![Supabase Logo](https://supabase.com/_next/image?url=https%3A%2F%2Ffrontend-assets.supabase.com%2Fwww%2Fd218d9190b87%2F_next%2Fstatic%2Fmedia%2Fsupabase-logo-wordmark--dark.b36ebb5f.png&w=384&q=75&dpl=dpl_9xPTPeSUKoDuygMmT5sPj6DB4mgG)](https://supabase.com/)
[Twitter](https://twitter.com/supabase)[GitHub](https://github.com/supabase)[Discord](https://discord.supabase.com/)[Youtube](https://youtube.com/c/supabase)
###### Product
  * [Database](https://supabase.com/database)
  * [Auth](https://supabase.com/auth)
  * [Functions](https://supabase.com/edge-functions)
  * [Realtime](https://supabase.com/realtime)
  * [Storage](https://supabase.com/storage)
  * [Vector](https://supabase.com/modules/vector)
  * [Cron](https://supabase.com/modules/cron)
  * [Pricing](https://supabase.com/pricing)
  * [Launch Week](https://supabase.com/launch-week)
  * [AI Builders](https://supabase.com/solutions/ai-builders)


###### Resources
  * [Support](https://supabase.com/support)
  * [System Status](https://status.supabase.com/)
  * [Become a Partner](https://supabase.com/partners)
  * [Integrations](https://supabase.com/partners/integrations)
  * [Brand Assets / Logos](https://supabase.com/brand-assets)
  * [Security and Compliance](https://supabase.com/security)
  * [DPA](https://supabase.com/legal/dpa)
  * [SOC2](https://supabase.com/security)
  * [HIPAA](https://forms.supabase.com/hipaa2)


###### Developers
  * [Documentation](https://supabase.com/docs)
  * [Supabase UI](https://supabase.com/ui)
  * [Changelog](https://supabase.com/changelog)
  * [Contributing](https://github.com/supabase/supabase/blob/master/CONTRIBUTING.md)
  * [Open Source](https://supabase.com/open-source)
  * [SupaSquad](https://supabase.com/supasquad)
  * [DevTo](https://dev.to/supabase)
  * [RSS](https://supabase.com/rss.xml)


###### Company
  * [Blog](https://supabase.com/blog)
  * [Customer Stories](https://supabase.com/customers)
  * [Careers](https://supabase.com/careers)
  * [Company](https://supabase.com/company)
  * [Events & Webinars](https://supabase.com/events)
  * [General Availability](https://supabase.com/ga)
  * [Terms of Service](https://supabase.com/terms)
  * [Privacy Policy](https://supabase.com/privacy)
  * Privacy Settings
  * [Acceptable Use Policy](https://supabase.com/aup)
  * [Support Policy](https://supabase.com/support-policy)
  * [Service Level Agreement](https://supabase.com/sla)
  * [Humans.txt](https://supabase.com/humans.txt)
  * [Lawyers.txt](https://supabase.com/lawyers.txt)
  * [Security.txt](https://supabase.com/.well-known/security.txt)


© Supabase Inc
Toggle theme

